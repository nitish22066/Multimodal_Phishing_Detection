{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2374680,"sourceType":"datasetVersion","datasetId":1434901}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-11T12:00:07.028812Z","iopub.execute_input":"2025-10-11T12:00:07.029162Z","iopub.status.idle":"2025-10-11T12:00:07.419281Z","shell.execute_reply.started":"2025-10-11T12:00:07.029106Z","shell.execute_reply":"2025-10-11T12:00:07.418144Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/web-page-phishing-detection-dataset/dataset_phishing.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/web-page-phishing-detection-dataset/dataset_phishing.csv\")\nprint(df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T12:00:09.590310Z","iopub.execute_input":"2025-10-11T12:00:09.590762Z","iopub.status.idle":"2025-10-11T12:00:09.800259Z","shell.execute_reply.started":"2025-10-11T12:00:09.590735Z","shell.execute_reply":"2025-10-11T12:00:09.799055Z"}},"outputs":[{"name":"stdout","text":"Index(['url', 'length_url', 'length_hostname', 'ip', 'nb_dots', 'nb_hyphens',\n       'nb_at', 'nb_qm', 'nb_and', 'nb_or', 'nb_eq', 'nb_underscore',\n       'nb_tilde', 'nb_percent', 'nb_slash', 'nb_star', 'nb_colon', 'nb_comma',\n       'nb_semicolumn', 'nb_dollar', 'nb_space', 'nb_www', 'nb_com',\n       'nb_dslash', 'http_in_path', 'https_token', 'ratio_digits_url',\n       'ratio_digits_host', 'punycode', 'port', 'tld_in_path',\n       'tld_in_subdomain', 'abnormal_subdomain', 'nb_subdomains',\n       'prefix_suffix', 'random_domain', 'shortening_service',\n       'path_extension', 'nb_redirection', 'nb_external_redirection',\n       'length_words_raw', 'char_repeat', 'shortest_words_raw',\n       'shortest_word_host', 'shortest_word_path', 'longest_words_raw',\n       'longest_word_host', 'longest_word_path', 'avg_words_raw',\n       'avg_word_host', 'avg_word_path', 'phish_hints', 'domain_in_brand',\n       'brand_in_subdomain', 'brand_in_path', 'suspecious_tld',\n       'statistical_report', 'nb_hyperlinks', 'ratio_intHyperlinks',\n       'ratio_extHyperlinks', 'ratio_nullHyperlinks', 'nb_extCSS',\n       'ratio_intRedirection', 'ratio_extRedirection', 'ratio_intErrors',\n       'ratio_extErrors', 'login_form', 'external_favicon', 'links_in_tags',\n       'submit_email', 'ratio_intMedia', 'ratio_extMedia', 'sfh', 'iframe',\n       'popup_window', 'safe_anchor', 'onmouseover', 'right_clic',\n       'empty_title', 'domain_in_title', 'domain_with_copyright',\n       'whois_registered_domain', 'domain_registration_length', 'domain_age',\n       'web_traffic', 'dns_record', 'google_index', 'page_rank', 'status'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom xgboost import XGBClassifier\nimport joblib\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom xgboost import XGBClassifier\nimport joblib\n# === Load and Prepare Data ===\ndf = pd.read_csv(\"/kaggle/input/web-page-phishing-detection-dataset/dataset_phishing.csv\")\n\n# Drop 'url' column (we assume features are already extracted)\ndf = df.drop(columns=[\"url\"])\n\n# Encode target\ndf['status'] = df['status'].map({'legitimate': 0, 'phishing': 1})\n\nX = df.drop(\"status\", axis=1)\ny = df[\"status\"]\n\n# Split into train/test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# === Define Base Models ===\nxgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', verbosity=0)\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nlr = LogisticRegression(max_iter=1000)\n\n# === Create Ensemble Model (VotingClassifier) ===\nensemble = VotingClassifier(\n    estimators=[('xgb', xgb), ('rf', rf), ('lr', lr)],\n    voting='soft'  # Use 'hard' for majority class, 'soft' for probabilities\n)\n\n# === Train Ensemble ===\nensemble.fit(X_train, y_train)\n\n# === Evaluate ===\ny_pred = ensemble.predict(X_test)\nprint(classification_report(y_test, y_pred))\n# === Save model and column order ===\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:45:48.088638Z","iopub.execute_input":"2025-08-01T06:45:48.088948Z","iopub.status.idle":"2025-08-01T06:45:51.066848Z","shell.execute_reply.started":"2025-08-01T06:45:48.088926Z","shell.execute_reply":"2025-08-01T06:45:51.065884Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.97      0.97      0.97      1157\n           1       0.97      0.97      0.97      1129\n\n    accuracy                           0.97      2286\n   macro avg       0.97      0.97      0.97      2286\nweighted avg       0.97      0.97      0.97      2286\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install tldextract","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:52:40.344245Z","iopub.execute_input":"2025-08-01T06:52:40.345021Z","iopub.status.idle":"2025-08-01T06:52:45.545724Z","shell.execute_reply.started":"2025-08-01T06:52:40.344987Z","shell.execute_reply":"2025-08-01T06:52:45.544760Z"}},"outputs":[{"name":"stdout","text":"Collecting tldextract\n  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from tldextract) (3.10)\nRequirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from tldextract) (2.32.4)\nCollecting requests-file>=1.4 (from tldextract)\n  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract) (3.18.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract) (2025.6.15)\nDownloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\nInstalling collected packages: requests-file, tldextract\nSuccessfully installed requests-file-2.1.0 tldextract-5.3.0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import classification_report\nimport joblib\nimport string\n\n# Load dataset\ndf = pd.read_csv(\"/kaggle/input/web-page-phishing-detection-dataset/dataset_phishing.csv\")\ndf = df[['url', 'status']].dropna()\n\n# Map status to binary\ndf = df[df['status'].isin(['phishing', 'benign'])]\ndf['status'] = df['status'].map({'phishing': 1, 'benign': 0})\n\n# === Character-Level URL Encoding ===\ndef encode_url(url, max_len=200):\n    charset = string.ascii_letters + string.digits + string.punctuation\n    char_to_int = {ch: i + 1 for i, ch in enumerate(charset)}  # start from 1\n    encoded = [char_to_int.get(c, 0) for c in url[:max_len]]\n    if len(encoded) < max_len:\n        encoded += [0] * (max_len - len(encoded))\n    return encoded\n\nX = np.array([encode_url(u) for u in df['url']])\ny = df['status'].values.astype(int)\n\n# === Train-Test Split ===\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# === Classifiers ===\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nxgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n\n# === Ensemble ===\nensemble = VotingClassifier(\n    estimators=[\n        ('rf', rf),\n        ('xgb', xgb)\n    ],\n    voting='hard'  # Switch to 'soft' after verifying predict_proba\n)\n\n# === Train & Predict ===\nensemble.fit(X_train, y_train)\ny_pred = ensemble.predict(X_test)\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:02:00.343634Z","iopub.execute_input":"2025-08-01T07:02:00.343964Z","iopub.status.idle":"2025-08-01T07:02:00.983832Z","shell.execute_reply.started":"2025-08-01T07:02:00.343941Z","shell.execute_reply":"2025-08-01T07:02:00.982957Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           1       1.00      1.00      1.00      1143\n\n    accuracy                           1.00      1143\n   macro avg       1.00      1.00      1.00      1143\nweighted avg       1.00      1.00      1.00      1143\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"joblib.dump(model, \"phishing_ensemble_ml_model.pkl\")\njoblib.dump(X.columns.tolist(), \"feature_columns.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:03:03.198984Z","iopub.execute_input":"2025-08-01T07:03:03.199287Z","iopub.status.idle":"2025-08-01T07:03:03.219079Z","shell.execute_reply.started":"2025-08-01T07:03:03.199267Z","shell.execute_reply":"2025-08-01T07:03:03.217345Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2577892916.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"phishing_ensemble_ml_model.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"feature_columns.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"],"ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'columns'","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"dictt={\n    'max_len': 200,\n    'char_to_int': {ch: i + 1 for i, ch in enumerate(string.ascii_letters + string.digits + string.punctuation)}\n}\njoblib.dump(dictt, \"feature_columns.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:04:55.092699Z","iopub.execute_input":"2025-08-01T07:04:55.092981Z","iopub.status.idle":"2025-08-01T07:04:55.101085Z","shell.execute_reply.started":"2025-08-01T07:04:55.092960Z","shell.execute_reply":"2025-08-01T07:04:55.100167Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"['feature_columns.pkl']"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"model = joblib.load(\"/kaggle/working/phishing_ensemble_ml_model.pkl\")\nchar2idx = joblib.load(\"/kaggle/working/url_encoding_metadata.pkl\")\nmaxlen = 200\n\ndef encode_url_for_inference(url):\n    url = url[:maxlen].ljust(maxlen)\n    return [char2idx.get(char, 0) for char in url]\n\ntest_url = \"http://www.crestonwood.com/router.php\"\nX_new = np.array([encode_url_for_inference(test_url)])\nprediction = model.predict(X_new)\nprint(\"Phishing\" if prediction[0] == 1 else \"Benign\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}